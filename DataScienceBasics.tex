\chapter{Data Science Basics}\label{ch_data_science}
\chapterauthor{Jeff Yoshimi}

% Add more discussion of tensors 

Although this book is about neural networks in cognitive science, and not about engineering uses of neural networks (see section \extref{typesOfResearch}), the field is now so connected to related areas like data science, statistics, and machine learning that some of the methods and concepts of those fields have become standard.\footnote{To be clear on terminology. Neural networks are used in the broad fields of machine learning and data science. Neural networks are one kind of machine learning model, and data science is a broader field focused on preparing and analyzing data, even when no machine learning model is used.}  These methods are especially important any time datasets are used to train networks, which is especially the case with supervised learning models. Broadly speaking, in this chapter we learn how to deal with tables of data, and also the different kinds of tables used to train neural network models.

\section{Data Science Workflow}

Here is a basic workflow that is common in data science and machine learning.

\begin{enumerate}
\item Getting the data. Describing it. Understanding its basic features. Coming up with useful column names or ``feature'' names. You might obtain data from an experiment, download data from a website, or be given a large table or spreadsheet. To get a better sense of the nature of the data used in a neural network, and the kinds of work needed to wrangle it in to a format that a network can process, several public repositories of machine learning and other kinds of data exist.\footnote{See: \url{https://archive.ics.uci.edu/ml/index.php} and \url{https://en.wikipedia.org/wiki/List_of_datasets_for_machine_learning_research}. Many other sources of data exist, of course, including US Census data, World Health organization data, etc. The website Kaggle has a large repository of datasets and machine learning tasks that can be pursued in a game-like competitive framework. Many public tools, like R, sklearn, Pytorch, and Tensorflow have datasets included.}  Special issues arise when using the very large datasets (``big data'') required to effectively train some machine learning models\footnote{Cf. \url{https://en.wikipedia.org/wiki/Big_data} and ETL \url{https://en.wikipedia.org/wiki/Extract,_transform,_load}.}, but we will focus on small datasets that are useful for illustrative purposes. 
\item Visualizing the data / EDA (Exploratory Data Analysis). Developing an initial feel for  data, often using visualizations.\footnote{See \url{https://en.wikipedia.org/wiki/Exploratory_data_analysis}.} Creating pictures that illustrate the main features of your data, which suggest how your machine learning task might be solved, e.g. finding data that show a correlation between some input data and the target data.
\item Preparing the data. Also called data wrangling. Creating useful features. Filling in missing data. Removing outliers. Discussed in more detail in section \ref{wrangling}.
\item Create and train a model. Choose a type of model and then train it. This is where  neural networks come in. In machine learning there are many kinds models, like multiple regression and decision trees and ensembles of models. But we focus on neural networks.
\item Assessing the model's performance on test data. We will see that it is often important to first train a model on one set of data, and then to validate the model on a separate set of data.
\end{enumerate}

We will not discuss obtaining data or exploratory data analysis here. We discuss data wrangling in section \ref{wrangling}. The rest of the chapter, and much of the rest of the book, is focused on creating and training neural network models. Assessing performance is briefly discussed in several places in this chapter and the next few chapters.

Of these steps, the main one in terms of learning is the step where we build and train a model. When the model is trained, we update its \emph{parameters}. Recall that we discussed parameters in the dynamical systems chapter, chapter \extref{ch_dst}. In a neural network, these parameters are usually weights and biases (chapter \extref{ch_act_functions}). Parameters change the dynamics of a dynamical system. For a recurrent network, that means they change what activations patterns occur over time. They change a phase portrait. For a feed-forward network, they change the input-output function the network produces. Feed-forward networks take an input vector and produce an output vector. The process of training a feed-forward network is the process of modifying the parameters in such  a way as to change the input-output function it implements. In chapter \extref{ch_supervised} we see how to update the parameters of a feed-forward network to achieve a desired input-output function, e.g. to make a network which recognizes letters or faces in images. In chapter \extref{ch_supervised_recurrent} we see how to update the parameters of a recurrent network to achieve desired dynamics, e.g. producing meaningful speech. 
% Ref to vector valued function. Reverse FF and recurrent?

However, in this chapter we also see all the other work that is involved in actually building a neural network model. Data must be gathered, analyzed, and cleaned up. And then we must partition our data in a special way in order to test how well it works not just on the data we trained it on, but also on new data it has never seen before.\footnote{A worked example illustrating many of the ideas in this chapter in tensor flow is here: \url{https://www.youtube.com/watch?v=-vHQub0NXI4}.}

\section{Datasets}

As discussed in chapter \extref{ch_intro}, neural networks are usually linked to an \emph{environment}, where that environment is often a simple table or spreadsheet. Even though we are just dealing with tables here, there are a lot of concepts and terms to master. We will take a  \glossary{dataset} to be a table of values to be used by a neural network. A row of a dataset is an \glossary{example}, \emph{instance}, or \emph{case}. A column of a dataset is a \glossary{feature} or \emph{attribute}. The columns of a dataset often correspond to the nodes of a network. Rows often correspond to inputs that will be sent to the input layer of a network, or used to describe desired outputs. These rows and columns can be transformed, partitioned, and manipulated in various ways, as we will see. 
% Other usages. Haykin uses "sample" for the entire training set. He also says: ``Random variables: Italic uppercase symbols are used for random variables.The sample value (i.e., one-shot realization) of a random variable is denoted by the corresponding italic lowercase symbol. For example, we write X for a random variable and x for its sample value.''   Deep learning book uses ``example''. Fausett using training sample sometimes. UCI Machine learning uses instances and attributesI, n psychology  rows are sometimes called ``subjects'' or ``items'', and columsn are covariates or variables. 
% Training sample is common, but a whole dataset is often a sample in the statistical sense, so it's confusing.
% Datasets have _distributions_ associated with them. EDA.
  
As an example, consider the Motor Trend Cars dataset  (``\emph{mtcars}''),  shown in Fig. \ref{cars_dataset}, which is included with the R statistical computing environment. The data is based on a 1974 issue of the car magazine \emph{Motor Trend}, which road-tested about 30 models of cars in the 1973-74 model year and measured a range of performance features.\footnote{See \url{https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/mtcars.html}. A neural network that processes this dataset is included with Simbrain as a script called \emph{backprop\_cars.bsh}. } The dataset contains 30 examples with 10 features each, 6 of which are shown (the row indices and the model names will not be sent to any neural network, so we don't count them as features). Notice that this table, as it stands, is not ready to be used by a neural network. The neural network can't deal with the names (which are strings, rather than numbers), and as we'll see, some of the values (like horsepower) are kind of big for a node that is only meant to deal with small numbers between -1 and 1. However, after a bit of processing, the data can be used to train a neural network to, for example, predict the fuel efficiency of a car based on its weight and number of cylinders.\footnote{A detailed discussion of this case is here: \url{https://www.youtube.com/watch?v=K4GZ51cozRs}.}

% Include code for this in image_masters
\begin{figure}[h]
\centering
\includegraphics[scale=0.6]{./images/CarsBase.png}
\caption[Screenshot of the Motor Trend Car Road Tests dataset included with R.]{A fragment of  the \emph {mtcars} dataset showing some of its examples (rows) and some of its features (columns) }
\label{cars_dataset}
\end{figure}

We can distinguish two main types of data. First, \glossary{categorical data}, also known as ``nominal data''. Categorical data can take one of a discrete list of values. For example playing cards can have one of four suits: hearts, diamonds, spades, or aces. The state one lives in can be one of 50 values. In the example in  Figure \ref{cars_dataset}, cylinders appears to be categorical, because there are three possible values for that feature: 4, 6, or 8 cylinders. For a neural network, these will be converted to numerical data using a ``one-hot-encoding'', as we will see. 

Second, \glossary{numerical data} is data that is already in the form of numbers. These numbers can either be real-valued (represented by floating point values in a computer) or integer-valued. Examples: age, income, house prices, hours of study, GPA, length, width, weight, caloric intake. In Figure \ref{cars_dataset} most of the columns are numerical. A few seem to be integers (displacement, horsepower), and others are clearly real-valued (weight, quarter-mile).\footnote{ In more rigorous treatments (derived from the study of scale types in measurement theory), ordinal, interval, and ratio scales are distinguished. We collapse interval and rational scales into numerical. Ordinal data (e..g first, second, and third in line) can often be treated as integers or using a one-hot encoding.}

To get a general sense of how datasets are used with neural networks, see Fig \ref{data_inputs}. Each column, each feature, is generally associated with the nodes of a network. The figure shows an input dataset, but we will see there are other types of datasets used with neural networks as well.

\begin{figure}[h]
\centering
\includegraphics[scale=.9]{./images/dataset_inputs.png}
\caption[Simbrain screenshot with graphical elements added by Pamela Payne.]{An example of an input dataset, which illustrates one standard way datasets are used with neural networks. Each row of the dataset is thought of as one input vector for the neural network.}
\label{data_inputs}
\end{figure}

\section{Data Wrangling (or Preprocessing)}\label{wrangling}

Raw data isn't usually ready to be fed to a neural network. Sometimes a dataset contains strings of text, images, sound files, and other structures that must be converted into a numerical format. Neural networks want \emph{numbers}, and they often want those numbers to be a certain way. So we have to pre-process the data in various ways. Our ultimate goal is typically to have a table all of whose cells contain numbers that lie within a fairly small range, like between -1 and 1 or between 0 and 1.\footnote{At that point our dataset has the form of a matrix (cf. Chapter \extref{ch_linear_algebra}), and mathematical operations of linear algebra can be applied to it.} That is, we want to end up with a dataset where each row is an input vector that can be fed to the input nodes of a neural network.

So we have work to do. We have to convert non-numerical data to single numbers. We have to fill in missing data. And even when all the data is numerical we must often do further things like rescaling the data. These operations correspond to \glossary{pre-processing} the data. This is sometimes called \glossary{data wrangling} or ``data munging''.\footnote{For a sense of some of the ways data can be wrangled, have a look at the \emph{scikit-learn} pre-processing library: \url{http://scikit-learn.org/stable/modules/preprocessing.html}.}  Here is how wikipedia defines it:

\begin{quotation}
Data munging or data wrangling is loosely defined as the process of manually converting or mapping data from one `raw' form into another format that allows for more convenient consumption of the data with the help of semi-automated tools.\footnote{\url{https://en.wikipedia.org/wiki/Data_wrangling}.} 
\end{quotation}

The process of wrangling data is usually understood as a step-wise workflow, a pipeline, where the data is obtained then transformed in stages until it is ready to be processed by a neural network. There are different ways  of understanding this workflow. Here is a generic version of a data wrangling workflow:
\begin{itemize}
\item Data cleaning: remove, fix, or otherwise deal with bad data. Fill in missing data.
\item Feature-extraction and feature-engineering: Transform data (e.g. text, images, audio files, DNA sequences) in to a numerical format and more generally produce a set of numerical features to be used by the neural network.
\item Rescaling: alter the numbers in the dataset to, for example, ensure that they are all in the range $(-1,1)$
\end{itemize}

The first step is \glossary{data cleaning} or ``data cleansing''. There might be stray characters that make it hard to import the data, or columns that are irrelevant to what you are trying to do. Often it helps to simply focus on a subset of columns or rows (\emph{subsetting}). A related cleansing step is dealing with missing data, using methods of \emph{ data imputation} to determine a policy for filling in missing data. Common techniques include filling in these cells  with 0's, or with the mean value of the column they are in.\footnote{See \url{https://towardsdatascience.com/how-to-handle-missing-data-8646b18db0d4} and \url{http://www.stat.columbia.edu/~gelman/arm/missing.pdf}.}

The next step, \glossary{feature-extraction}  involves converting non-numeric data in to a numerical form suitable for a neural network. Images, movies, audio, DNA sequences, and of course, text, are all non-numeric data that must be converted to a numerical format.\footnote{Also see \url{http://scikit-learn.org/stable/modules/feature_extraction.html}} This is often the most involved and  most important step in building a working model. Many of the earliest connectionist models (e.g. Nettalk) relied on clever ways of representing written and spoken speech in a vectorized way that could be fed to a network.

We are construing this step quite broadly, to include any steps involved in coming up with features (numerical columns) for a dataset, from flattening a matrix, to combining other features to create new features. The latter is sometimes also called \emph{feature-engineering}, where a new feature is designed for use in training a model, e.g. deciding not to feed a neural network height and width information separately, but rather to feed it the ratio of the height to the width of an image, which might yield better results for some applications. Another example in the \emph{mtcars} dataset would be to take the model of a car and then consult a database online to find new features of the cars.\footnote{In competitive machine learning, as in Kaggle, often the best solutions are based on clever feature engineering, more so than anything in the machine learning model itself.}

% Time, date as features, which raise special issues
% Acoustic features is itself a cog-sci discussion. So this overlaps cog-sci. See Magnuson talk.
% Work more on the feature discussion in relation to deep learning, which is basically a massive feature detector pre-pended to a standard 3 layer ff network.
Here are some examples of feature extraction in this fairly broad sense. 
\begin{itemize}
\item Taking a feature like the model of a car, state of residence, or gender, and converting it into a vector of binary values. There are several ways to do this, but the most common is using a \glossary{One-hot} or ``one-of-$k$'' encoding, which is a type of coding that converts categorical data to binary vectors.\footnote{See \url{https://en.wikipedia.org/wiki/One-hot}.} If we have categories Fish, Swiss, and Gouda, then we can use a one-of-three encoding and represent Fish as $(1,0,0)$, Swiss as $(0,1,0)$, and Gouda as $(0,0,1)$. In a bank of nodes this corresponds to one node being active (``hot'') and the other nodes being inactive, hence ``one-hot'' encoding. One is hot, and the other is not. For example, in the cars dataset, we can represent 4-cylinder, 6-cylinder, and 8-cylinder by a one-hot (in this case one-of-3) encoding, as in Fig. \ref{cars_onehot}. Notice that the cylinder column in Fig. \ref{cars_dataset} has been  replaced by three columns. Which column has a ``1'' in it indicates whether the car is 4, 6, or 8 cylinders. These are also called dummy or indicator variables in psychology.\footnote{They are, in a way, localist, since they will lead just one node to be active. Cf IAC networks and the discussion of localist vs. distributed representations in chapter \extref{ch_intro}.}
\item Taking a matrix and ``flattening'' it into a vector that can be treated as a row of a dataset. This is often done with images. Sometimes an even more complex object, a \emph{tensor}, must be flattened.\footnote{A tensor is like a generalized matrix, a multi-dimensional array. A vector is a 1st-order is a vector, a 2nd-order tensors is a matrix, and a 3d-order tensor is a set of matrices, a 4th order tensor is a set of sets of matrices, etc. See \url{https://en.wikipedia.org/wiki/Tensor}.}  Color images are often represented as three separate pixel  images, corresponding to red, green, and blue channels. So we have three matrices, that must be flattened and concatenated to produce one long vector, which is then a proper row of a dataset that can be fed to a network.
\item Converting strings of texts to vectors. Thus the word ``red'' might become the vector $(1,0,1,0,1,1)$. Techniques for converting linguistic data to vectors are sometimes referred to as methods of \emph{word embedding}. Word embedding is a major area of research in its own right.\footnote{ See \url{https://en.wikipedia.org/wiki/Word_embedding}. A famous algorithm for word embedding is word2vec. See \url{https://www.tensorflow.org/tutorials/word2vec}.}
\item Dividing a sound file into smaller time windows and converting those ``clips'' of audio into vectors, often using signal processing techniques like Fourier analysis.
\item Hand coding video or audio data in some way, e.g. counting how many times a participant in a videotaped experiment hits a doll, or how many questions a participant asks. This kind of technique is often used in experimental settings, e.g. in psychology.\footnote{See \url{https://en.wikipedia.org/wiki/Coding_(social_sciences)}.}
\end{itemize}
% Representation / representation learning from deep learning book. How data is represented is the first step in a machine learning 
% Chris Kello quote. ``It all depends on your representation. You win or lose based on that.''
% E.g. the old https://en.wikipedia.org/wiki/Wickelphone stuff

\begin{figure}[h]
\centering
\includegraphics[height=50mm]{./images/CarsOneHot.png}
\caption[Screenshot of the Motor Trend Car Road Tests dataset included in R.]{Convert cylinders to a binary ``one-hot'' encoding.}
\label{cars_onehot}
\end{figure}

Having coded all data as numerical, additional work often remains to be done, in particular, \glossary{rescaling} the data so that they fit in some standard range, e.g. $(0,1)$ or $(-1,1)$. Figure \ref{cars_dataset_scaled} shows the \emph{mtcars} dataset of figure \ref{cars_onehot} after all columns have been rescaled to lie between 0 and 1. A simple and common way to do this for positive valued data is to divide each entry by the maximum value in that column. A similar method works on data that contains negative values. This is sometimes called \emph{min-max scaling}.\footnote{It can also be called ``normalization'' but that term is confusing because it is used in linear algebra in slightly different way.} This method ensures that all data are in the range  $(0,1)$. Another method is standardizing, where each value in a column is centered at the mean and scaled by standard deviation. This makes it intuitive to interpret data. If we standardize a column, then the 0's correspond to average values, positive values are above average, and negative values are below average (in statistics this is sometimes called a $z$-score). Anything above 1 is unusually large, and similarly for values below -1. However this method allows values above 1 and below -1. 

\begin{figure}[h]
\centering
\includegraphics[height=50mm]{./images/CarsScaled.png}
\caption[Screenshot of Motor Trend Car Road Tests dataset included with R.]{Data from Fig. \ref{cars_dataset} rescaled to $(0,1)$.}
\label{cars_dataset_scaled}
\end{figure}
% Rescale the one-hot data instead

\section{Datasets for Neural Networks}

When we train a neural network we update its parameters--its weights and biases--so that it can learn to do useful things. This is what our brains do when we learn, updating synaptic strengths in order to function more effectively. As we will see, for unsupervised learning, we take an input dataset and train it to pick up statistical features of the data. For supervised learning we take ``target data'' or ``labeled data'' and use it to train a network to do some desired thing.\footnote{Note that the term ``label'' is associated specifically with classification tasks, where an input is sorted into one of a finite set of categories. Think of labeling images as cat vs. dog. But not all training tasks are like that; regression tasks for example associate inputs with real-valued targets. ``Target data''  is thus a more general term. However, the terminology of ``labeled data''  has become standard, and  is snappier than ``input-target dataset''. We will use both terminologies interchangeably.}
% Reference to classification / regression discussion once that's done

To support these tasks, we must define several standard types of datasets:
\begin{itemize}
\item \textbf{Input dataset}: each row contains an input vector that can be sent to a neural network. This idea is illustrated in Fig. \ref{data_inputs}.
\item \textbf{Output dataset}: each row contains an output vector that has been recorded from a neural network. These are also called ``predictions''. 
\item \textbf{Target dataset (labels)}: each row contains a target output vector we'd like a neural network to produce for a given input vector. The target dataset is a set of \emph{desired outputs}, a set of labels.
\item \textbf{Labeled dataset}: an input dataset and a corresponding target dataset. Note that the two datasets must have the same number of rows. This idea is illustrated in Fig. \ref{supervised_learning}.
\end{itemize}
Examples of each type of dataset are shown in Fig. \ref{datasetTypes}.
% Graph showing availability of data vs. labeled data. 

% Include standard labels, like x for inputs,  y for labels, $\hat{y}$ for predictions

An \glossary{input dataset} contains input vectors to be sent to the input nodes of a neural network. Each row of an input dataset is a point in the input space of a neural network. Input datasets are used for all kinds of learning tasks, supervised and unsupervised. 

An \glossary{output dataset} is \emph{generated} from an input dataset. We feed each row of the input dataset to a network, and record the resulting output vector. Thus an output dataset will have as many rows as the input dataset used to train it. The phrase ``output dataset'' is non-standard. Since these are often interpreted as predictions given a set of inputs, this table is sometimes referred to as a set  of ``predictions''. 

A \glossary{target dataset} contains the outputs we \emph{want} the network to produce. These can be thought of as desired outputs. These targets are also called ``labels'', for classification tasks, described below. We compare an output dataset with a target dataset to produce an error, discussed in chapter \extref{ch_supervised}. Like an output dataset, a target dataset will have as many rows as a corresponding input dataset. 

A \glossary{labeled dataset} or \emph{labeled data} or \emph{input-target dataset} is a concatenation of two tables, an input and a target dataset. We can represent this by simply concatenating the two datasets and separating them with double vertical lines, as in the right-most panel of Fig. \ref{datasetTypes}. This is perhaps the most common type of dataset to consider, since it is a specification of a supervised learning task. Labeled data is often difficult to obtain, because we can't simply gather it ``from the world.''  If we take a bunch of pictures of people's faces and transform the data then we have our input dataset. But it is an extra step for a human to come in and label each face as male or female, so that we can confirm that a machine can also do the job. The contrast to labeled  data  is an input dataset by itself, or what is sometimes referred to as ``unlabeled data''. 

\begin{figure}[h]
\centering
\includegraphics[width=0.7\textwidth]{./images/datasetTypes.png}
\caption[Jeff Yoshimi.]{From left to right: an input dataset, output dataset, target dataset, and labeled dataset.}
\label{datasetTypes}
\end{figure}

\section{Generalization and Testing Data }

% Mention car network from videos and how we can train it then use it to predict new data
One attractive feature of neural networks is that even if they have been trained on a specific dataset, they will tend to generalize well to new patterns they weren't trained on. This is easy to see with the 3-object detector in Simbrain, discussed in section \extref{intro_comp_nn}. Try plugging in inputs it has not seen before, and it will still do well. This is a psychologically realistic property of neural networks. Suppose I have only ever seen two pineapples. My neural network was only trained on two  pineapples. But I manage to correctly classify many other pineapples that I've never seen, even though they produce slightly different patterns on my eye. Our neural networks are good at \glossary{generalization}, at extrapolating from what they have seen to new things they have not seen.

% Mention relevant psychology studies below
On the other hand, sometimes the specific inputs a neural network is trained on are, in a sense, \emph{too} specific. Ideally we have diverse inputs that allow us to deal well with new situations. But sometimes people are exposed to  data that is narrow and that leads to poor generalization. If you grow up in the forest you will be very good at classifying trees, but not so good at classifying buildings. This is the origin of biases and stereotypes and linguistic accents. 

% Underfitting. Bias variance tradeoff. Glossary below
This issue also comes up in neural networks. When you train a network on a labeled dataset, it can learn to be very good at predicting the target data you provide it. However, it might end up being \emph{too} finely tuned on that data, and thus fail to do well with new data. This is called \emph{overfitting}. We want to build models that are not overfit to the data they were trained on. We want them to do well not just on the data we trained them on, but also on new data they have never seen. How well does the network generalize to new data?  This is also referred to as ``out of sample'' performance (how well does a model do outside of the same data it was trained on). We train a network on 30 cars, and then test it on a new car it's never seen before. Or we train a network to classify 100 letters, but then we give it new letters it's never seen before. A good network can generalize from what it's been trained on, to new data.

To deal with this issue, we partition a labeled dataset into two subsets. We train the network on one subset of data, and then test it on another set of data that we have ``held out'', to see how well the network generalizes. These two subsets are a training subset and a testing subset of a labeled dataset.

A \glossary{training subset} or \emph{training dataset} or \emph{training data} is a subset of a labeled dataset used for training your model.

A  \glossary{testing subset} or \emph{testing dataset} or \emph{testing data} is a subset of a labeled dataset used for testing your model on new inputs. This is data that is held out to see how well a model generalizes. 

The idea is illustrated in Fig. \ref{trainTest}. The idea is that we first train the network using training data, and then validate it using testing data.\footnote{In a machine learning context, we might also distinguish working from production data. Working data includes all the data mentioned above, used to train and test and validate a machine learning model. Production data is then data the machine learning model encounters in the "real world" when it has been deployed and is being used.} 

\begin{figure}[h]
\centering
\includegraphics[scale=0.3]{./images/trainTest2.png}
\caption[Jeff Yoshimi.]{The rows of a labeled dataset (with inputs and targets) divided in to a training and a  testing subset. The training subset is used to train our model, and the testing subset is used to validate how well it generalizes. Thus we end up with four tables: (1) training inputs, (2)  training targets or labels, (3) testing inputs, and (4) testing targets. }
\label{trainTest}
\end{figure}

So what we actually often end up with, in supervised learning, is four tables. (1) Training inputs, (2) test inputs, (3) training targets, and (4) test targets. The training inputs and targets are used to train the model. The test inputs and targets are used to determine how well it performs on new data. In a model we might label these \code{train\_inputs}, \code{train\_targets}, \code{test\_inputs}, and \code{test\_targets}. 

% Expand on batches
In practice, even more complex ways of partitioning labeled data into training and testing subset are used, for example splitting the data into training and testing sets different ways on different passes.\footnote{The more general topic is cross validation, see \url{https://en.wikipedia.org/wiki/Cross-validation_(statistics)} and \url{http://scikit-learn.org/stable/modules/cross_validation.html}.} The particular training subset used in a given stage of training is often referred to as a ``batch''. We are keeping things simple here for illustrative purposes.
 
% There is much more to say about this topic. In particular, when a neural network or other model overfits--performing well on the training subset but poorly on the testing subset--\emph{regularlization} methods are used to address the problem.\footnote{See \url{http://neuralnetworksanddeeplearning.com/chap3.html}} But we will not discuss these topics further here.

\section{Supervised vs. Unsupervised Learning}

% We can now begin consider some of the specific \emph{tasks} that networks can be given, which determines in what way we train them and get them to learn. Possibly define the term ``task'' generically. See deep learning book.
% Links to cognitive science. Many circuits seem to use unsupervised learning. Supervised less so, except through RL. But also PP. Error signals do seem to be used all over the place. So an odd kind of resurgence of supervised learning in the brain.

We can distinguish two general ways of training a feed-forward neural network: supervised methods, where we tell the network what it should do with each input, and unsupervised methods, where we don't tell the network what we want it to do, but it figures out on its own (without a ``supervisor'') what to do. These concepts apply to recurrent networks as well, but we'll focus on feed-forward networks for now.

\begin{figure}[h]
\centering
\includegraphics[width=0.4\textwidth]{./images/dataset_supervised.png}
\caption[Simbrain screenshot with graphical elements added by Pamela Payne.]{Illustration of how supervised learning works.}
\label{supervised_learning}
\end{figure}

\glossary{Unsupervised learning}  is learning without a teacher, which is covered in chapters \extref{ch_unsupervised} and \extref{ch_unsupervised_recurrent}, and which we saw is a general principle of neural development in chapter \extref{ch_neuro}. We don't tell the network what we want. It must adapt on its own, discovering statistical patterns in the inputs it is exposed to. We don't teach or train the network. There is just an input dataset. There is no target data. This is in a way more realistic. After all, humans and animals don't constantly have a parent or teacher around telling them what's right or wrong. It can also be useful in  machine learning, since we oftentimes don't have training data available (hence the phrase ``unlabeled data'').
% (compare latent learning; rats learn whether or not they are rewarded).

In the case of \glossary{supervised learning}, we tell the network what we want it to do. There is a teacher or trainer and so we have a labeled dataset. It's kind of like a parent telling a child, ``No, that's wrong, this should be the answer!''   For feed-forward networks this means we give it a labeled dataset and say ``implement that''! We train the network to perform a set of input-output associations. The general schema is illustrated in figure \ref{supervised_learning}. We train a network using a supervised learning algorithm using a labeled dataset, which includes \emph{two} tables, one for the inputs (the input dataset), and another for the outputs that we \emph{should} get for each input (the target dataset). As each row of an input dataset is  fed to the network, a corresponding row of a target dataset is used to determine how the network should respond. 

Supervised learning is a huge topic, and will be covered in chapter \extref{ch_supervised}. Almost all of the major examples of things neural networks have done--drive cars, classify letters, translate languages or speech signals, etc. (see chapter \extref{ch_intro})--were achieved using supervised learning. However these methods are not just useful in engineering. They have also been used to used in connectionism and computational cognitive neuroscience to study the kinds  of representations the brain develops based on its exposure to inputs. Recall, for example, the discussion of the cerebellum and basal ganglia in chapter \extref{ch_neuro}, both of which are thought to learn via supervised learning.

